{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELQbuipMsfGV"
      },
      "source": [
        "# AI for Cyber Security Spam email detection\n",
        "\n",
        "Spam Email detection\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/venky73/spam-mails-dataset/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRnxriJ9sssi"
      },
      "source": [
        "\n",
        "Machine learning provides a powerful way to combat spam emails. Here's the basic process:\n",
        "\n",
        "\n",
        "* **Data Preparation:** Collect a labeled dataset of emails (spam and non-spam). Text data is cleaned and transformed into numerical features (e.g., word counts, presence of certain phrases).\n",
        "\n",
        "* **Model Selection:** Choose a machine learning algorithm like Naive Bayes, Support Vector Machines (SVMs), or Random Forests.\n",
        "\n",
        "* **Training:** Train the model on the prepared dataset, allowing it to learn patterns that distinguish spam from legitimate emails.\n",
        "Prediction: The trained model can now classify new, unseen emails as spam or not spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYxQzpo01J2K"
      },
      "source": [
        " It discusses Enron emails and the data was collected from Enron1 folder.\n",
        "\n",
        " Link: https://www2.aueb.gr/users/ion/data/enron-spam/\n",
        "\n",
        " The dataset contains two folders of emails, spam and ham, each containing 517 emails.\n",
        "\n",
        " The emails are labelled as\n",
        " * spam\n",
        " * ham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqkcBFPzuivs"
      },
      "source": [
        "## Importing Required Liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lj6ESXw6S5R"
      },
      "outputs": [],
      "source": [
        "# Import Required liberaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qoi1Qhj0uuD3"
      },
      "source": [
        "## Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4w7Fkiy6VUM"
      },
      "outputs": [],
      "source": [
        "# import the dataset using pandas liberary and view initial roes of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy5s-6Dc6YzW"
      },
      "outputs": [],
      "source": [
        "# visulaize one sample of the data with its label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2q1Hqd-6bt9"
      },
      "outputs": [],
      "source": [
        "# visualize another sample of the other calss to get a clear picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knnesb3w1Dku"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27LUaNjR6frC"
      },
      "outputs": [],
      "source": [
        "# rename column 0 as 'word_count'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Fb-vN7A6h9N"
      },
      "outputs": [],
      "source": [
        "# visualize initial rows of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C3GUAAJ3d5L"
      },
      "source": [
        "analyzing the word count of ham messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww0WogNW6qEq"
      },
      "outputs": [],
      "source": [
        "# analyze the word count of emails which come under ham category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXNLhanu3k3s"
      },
      "source": [
        "analyzing word count of spam messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCA-AdPo6v-m"
      },
      "outputs": [],
      "source": [
        "# analyze the word count of emails which come under ham category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnQvcSWU-vu8"
      },
      "source": [
        "## ML Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwBCyn8x60Oo"
      },
      "outputs": [],
      "source": [
        "# import tfidfVectorizer from sklearn \n",
        "# create a tfidf instance and apply it to the text column as indipendent variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsWeF272-023"
      },
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSnk9uCL63Cy"
      },
      "outputs": [],
      "source": [
        "# check the shape of the indipendent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP0R-gVW651G"
      },
      "outputs": [],
      "source": [
        "# create a dependent variable from the labels in he dataset as dependent variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXZAWEZb6821"
      },
      "outputs": [],
      "source": [
        "# check the shape of the dependent variabel "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp_1E3zs7ADq"
      },
      "outputs": [],
      "source": [
        "# split the data into test and train sets using train_test_split liberary from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGgxDG1d7Dqo"
      },
      "outputs": [],
      "source": [
        "# check the shape of the train and test variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OYN4s2R-8yH"
      },
      "source": [
        "### Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW-WemT-7GmB"
      },
      "outputs": [],
      "source": [
        "# import logistic regression model from sklearn\n",
        "# train the model on the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U77Cop-S_Avk"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcN1pnVK7JSL"
      },
      "outputs": [],
      "source": [
        "# evaluate the mdoel using the test data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOiB76wX7L4I"
      },
      "outputs": [],
      "source": [
        "# calculate the accuracy scores of the model  \n",
        "# calculate the precission, reacall, and f1 score "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
